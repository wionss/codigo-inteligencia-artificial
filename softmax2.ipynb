{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52730fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 9.018445613510451\n",
      "100 : 1.1039301493181293\n",
      "200 : 0.7810148018380971\n",
      "300 : 0.6458956289267309\n",
      "400 : 0.5648777615569984\n",
      "500 : 0.5082476154115567\n",
      "600 : 0.46537160787055315\n",
      "700 : 0.43137364899835196\n",
      "800 : 0.4036040523306157\n",
      "900 : 0.3804145679295034\n",
      "1000 : 0.36069730579888437\n",
      "1100 : 0.3436754020770278\n",
      "1200 : 0.3287920495022447\n",
      "1300 : 0.3156394317455427\n",
      "1400 : 0.3039117577228412\n",
      "1500 : 0.2933746493638767\n",
      "1600 : 0.283844573134881\n",
      "1700 : 0.27517457133826534\n",
      "1800 : 0.267244443199748\n",
      "1900 : 0.2599541752822546\n",
      "2000 : 0.253219724860029\n",
      "2100 : 0.24697031193394592\n",
      "2200 : 0.24114639686069222\n",
      "2300 : 0.23569788970611136\n",
      "2400 : 0.2305825301987058\n",
      "2500 : 0.22576449621903513\n",
      "2600 : 0.2212132585801222\n",
      "2700 : 0.21690265517139012\n",
      "2800 : 0.21281014524668262\n",
      "2900 : 0.20891620833000726\n",
      "3000 : 0.2052038576210439\n",
      "3100 : 0.2016582423633947\n",
      "3200 : 0.19826631869901462\n",
      "3300 : 0.19501657396705468\n",
      "3400 : 0.19189879410321425\n",
      "3500 : 0.18890386714271537\n",
      "3600 : 0.18602361790334784\n",
      "3700 : 0.1832506700422851\n",
      "3800 : 0.18057833214402616\n",
      "3900 : 0.17800050458061664\n",
      "4000 : 0.1755116038512986\n",
      "4100 : 0.1731065011692538\n",
      "4200 : 0.17078047232380608\n",
      "4300 : 0.1685291562879341\n",
      "4400 : 0.16634852055849414\n",
      "4500 : 0.16423483169202532\n",
      "4600 : 0.16218462986072296\n",
      "4700 : 0.16019470649485149\n",
      "4800 : 0.15826208423900015\n",
      "4900 : 0.15638399858085333\n",
      "5000 : 0.15455788064875592\n",
      "5100 : 0.15278134083199968\n",
      "5200 : 0.1510521530503865\n",
      "5300 : 0.1493682396699473\n",
      "5400 : 0.14772765720515463\n",
      "5500 : 0.14612858303840534\n",
      "5600 : 0.14456930340576102\n",
      "5700 : 0.14304820284135925\n",
      "5800 : 0.1415637551602548\n",
      "5900 : 0.14011451592566074\n",
      "6000 : 0.13869911622950162\n",
      "6100 : 0.1373162575416616\n",
      "6200 : 0.13596470736173188\n",
      "6300 : 0.13464329542933207\n",
      "6400 : 0.13335091029820437\n",
      "6500 : 0.13208649613754597\n",
      "6600 : 0.13084904967819708\n",
      "6700 : 0.12963761726411377\n",
      "6800 : 0.12845129199890676\n",
      "6900 : 0.1272892109942758\n",
      "7000 : 0.1261505527346117\n",
      "7100 : 0.12503453457288655\n",
      "7200 : 0.12394041036989847\n",
      "7300 : 0.12286746828406052\n",
      "7400 : 0.121815028713676\n",
      "7500 : 0.12078244238893454\n",
      "7600 : 0.11976908860715751\n",
      "7700 : 0.11877437360227332\n",
      "7800 : 0.11779772903805934\n",
      "7900 : 0.11683861061416356\n",
      "8000 : 0.11589649677409349\n",
      "8100 : 0.11497088750499529\n",
      "8200 : 0.11406130321994683\n",
      "8300 : 0.11316728371449312\n",
      "8400 : 0.1122883871901603\n",
      "8500 : 0.11142418933862216\n",
      "8600 : 0.11057428248103877\n",
      "8700 : 0.10973827475782122\n",
      "8800 : 0.10891578936471372\n",
      "8900 : 0.1081064638316268\n",
      "9000 : 0.10730994934112063\n",
      "9100 : 0.10652591008383272\n",
      "9200 : 0.1057540226484802\n",
      "9300 : 0.10499397544434723\n",
      "9400 : 0.10424546815440107\n",
      "9500 : 0.10350821121736821\n",
      "9600 : 0.10278192533724813\n",
      "9700 : 0.10206634101885499\n",
      "9800 : 0.10136119812805802\n",
      "9900 : 0.10066624547544906\n",
      "10000 : 0.09998124042220427\n",
      "10100 : 0.09930594850693378\n",
      "10200 : 0.09864014309233468\n",
      "10300 : 0.09798360503048152\n",
      "10400 : 0.09733612234561201\n",
      "10500 : 0.09669748993329336\n",
      "10600 : 0.09606750927489288\n",
      "10700 : 0.09544598816631998\n",
      "10800 : 0.09483274046006213\n",
      "10900 : 0.09422758581959839\n",
      "11000 : 0.09363034948534292\n",
      "11100 : 0.09304086205134367\n",
      "11200 : 0.0924589592520372\n",
      "11300 : 0.09188448175843816\n",
      "11400 : 0.0913172749832173\n",
      "11500 : 0.09075718889419553\n",
      "11600 : 0.09020407783585008\n",
      "11700 : 0.08965780035849348\n",
      "11800 : 0.08911821905484116\n",
      "11900 : 0.08858520040373385\n",
      "12000 : 0.08805861462082079\n",
      "12100 : 0.08753833551604115\n",
      "12200 : 0.0870242403577647\n",
      "12300 : 0.08651620974346524\n",
      "12400 : 0.08601412747680638\n",
      "12500 : 0.08551788045101565\n",
      "12600 : 0.0850273585384148\n",
      "12700 : 0.08454245448595828\n",
      "12800 : 0.08406306381661369\n",
      "12900 : 0.08358908473639687\n",
      "13000 : 0.08312041804685195\n",
      "13100 : 0.08265696706274595\n",
      "13200 : 0.08219863753472766\n",
      "13300 : 0.08174533757668467\n",
      "13400 : 0.0812969775975191\n",
      "13500 : 0.08085347023705412\n",
      "13600 : 0.0804147303057788\n",
      "13700 : 0.07998067472813693\n",
      "13800 : 0.07955122248906855\n",
      "13900 : 0.07912629458351601\n",
      "14000 : 0.07870581396861362\n",
      "14100 : 0.07828970551828537\n",
      "14200 : 0.07787789597998335\n",
      "14300 : 0.0774703139333032\n",
      "14400 : 0.07706688975022022\n",
      "14500 : 0.07666755555669068\n",
      "14600 : 0.0762722451953656\n",
      "14700 : 0.0758808941891645\n",
      "14800 : 0.07549343970545438\n",
      "14900 : 0.0751098205205794\n",
      "Accuracy : 0.9758285714285714\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mnist_data = fetch_openml('mnist_784', version=1)\n",
    "X = mnist_data['data']      # pandas core frame dataframe\n",
    "y = mnist_data['target']    # pandas core series series\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "X = np.c_[np.ones([X.shape[0], 1]), X]\n",
    "X = X / 255.\n",
    "# print(X[0])\n",
    "\n",
    "\n",
    "def target_categories_to_numbers(y_):\n",
    "    y_numbers = np.zeros(y_.shape[0])\n",
    "    for i in range(10):\n",
    "        y_numbers[np.where(y_ == np.unique(y_)[i])] = i\n",
    "\n",
    "    return y_numbers.astype(int)\n",
    "\n",
    "\n",
    "def numbers_to_one_zero_encoding(y_):\n",
    "    y_one_zero_matrix = np.zeros((y_.shape[0], 10))\n",
    "    y_one_zero_matrix[np.arange(y_.shape[0]), y_] = 1\n",
    "\n",
    "    return y_one_zero_matrix\n",
    "\n",
    "\n",
    "numbers_y = target_categories_to_numbers(y)\n",
    "one_zero_matrix_y = numbers_to_one_zero_encoding(numbers_y)\n",
    "\n",
    "X_training, X_testing, y_training, y_testing = train_test_split(X, one_zero_matrix_y, test_size=0.2, random_state=14)\n",
    "\n",
    "\n",
    "def linear_predictor(w, x):     # W is a 785x10 matrix  # X is a number_of_values x 785 matrix\n",
    "    return np.matmul(x, w)      # number_of_values x 10\n",
    "\n",
    "\n",
    "def softmax_predictor(linear_value):        # linear value is a number_of_value x 10 matrix\n",
    "    # print(linear_value[0])\n",
    "    exponent_matrix = np.exp(linear_value)  # matrix of the same size as linear_value\n",
    "\n",
    "    sum_of_exponential_values = np.sum(exponent_matrix, axis=1, keepdims=True)\n",
    "    # matrix where each of the rows have been reduced to a single column\n",
    "    softmax_prediction_ = exponent_matrix / sum_of_exponential_values\n",
    "    return softmax_prediction_\n",
    "    # each row is divided by the same sum value irrespective of column\n",
    "\n",
    "\n",
    "def get_output_from_softmax_predictor(softmax_prediction_):  # softmax prediction is a number_of_value x 10 matrix\n",
    "    return np.argmax(softmax_prediction_, axis=1)\n",
    "\n",
    "\n",
    "def weight_update(softmax_prediction_, w, y_, x, alpha):     # calculated likelihood maximization through gradient\n",
    "    diff = y_ - softmax_prediction_                          # ascent\n",
    "    gradient = np.matmul(x.T, diff)         # diff is num_of_value x 10 matrix, x.T is 785 x num_of_value matrix\n",
    "    w = w + alpha * gradient                # hence gradient is 785 x 10 matrix which is indeed also the size of\n",
    "    # print(w[0])                             # our weight matrix\n",
    "    return w\n",
    "\n",
    "\n",
    "def cost_function(softmax_prediction_, y_):\n",
    "    cost_ = -np.mean(np.sum(y_ * np.log(softmax_prediction_ + 1e-6), axis=1))\n",
    "    return cost_\n",
    "\n",
    "\n",
    "learning_rate = 0.0001\n",
    "\n",
    "np.random.seed(14)\n",
    "W = np.random.randn(785, 10)\n",
    "\n",
    "epochs = 15000\n",
    "batch_size = 7000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # for i in range(0, X_training.shape[0], batch_size):\n",
    "    #     X_batch = X_training[i:i + batch_size]\n",
    "    #     y_batch = one_zero_matrix_y[i:i + batch_size]\n",
    "    X_batch = X_training[:batch_size]\n",
    "    y_batch = y_training[:batch_size]\n",
    "\n",
    "    linear_prediction = linear_predictor(W, X_batch)\n",
    "    # print(linear_prediction[0])\n",
    "    softmax_prediction = softmax_predictor(linear_prediction)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        cost = cost_function(softmax_prediction, y_batch)\n",
    "        print(epoch, cost, sep=\" : \")\n",
    "\n",
    "    W = weight_update(softmax_prediction, W, y_batch, X_batch, learning_rate)\n",
    "\n",
    "\n",
    "def test_model(x_test, y_test, w):\n",
    "    linear_test_prediction = linear_predictor(w, x_test)\n",
    "    softmax_test_prediction = softmax_predictor(linear_test_prediction)\n",
    "    final_prediction = get_output_from_softmax_predictor(softmax_test_prediction)\n",
    "\n",
    "    accuracy = np.mean(numbers_to_one_zero_encoding(final_prediction) == y_test)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "print(f'Accuracy : {test_model(X_testing, y_testing, W)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2a2090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdcee9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
